# 感知机

## 1. 什么是感知机

&ensp;&ensp;**感知机**是美国学者Frank Rosenblatt在1957年提出的， 是神经网络(深度学习)的基础。

感知机接收多个输入信号，输出一个信号。 举个直观的例子，如图1：

![avatar](https://github.com/TangBaron/Neural-Network-Manual-Implementation/tree/master/1.%E6%84%9F%E7%9F%A5%E6%9C%BA/1.png)

&ensp;&ensp;图中 x1, x2就是两个输入值，y是输出的信号。 w<sub>1</sub>和w<sub>2</sub>是权重。 深度学习一个概念是**"神经元"**, 图中的x<sub>1</sub> x<sub>2</sub>和y都可以理解为**"神经元"**， x1和x2是输入神经元， y是输出神经元。 输入神经元的信号送往神经元时，会分别乘以固定权重，得到(w<sub>1</sub>x<sub>1</sub>)。 神经元会计算得到的两个结果的总和。 如果这个综合大于某个阈值， 输出为1，代表神经元被“激活”，反之小于该阈值，则输出为0， 表示神经元未被激活。

&ensp;&ensp;以上就是感知机的运行原理，是不是非常简单！不要有丝毫怀疑，这就是目前深度学习网络的基础！为了直观理解，我们把上述的过程写成公式如下:

![avatar](https://github.com/TangBaron/Neural-Network-Manual-Implementation/tree/master/1.%E6%84%9F%E7%9F%A5%E6%9C%BA/2.png)

公式中的θ表示阈值, 我们其实可以把阈值理解为**偏置**， 这也是神经网络中的一个重要概念。

## 2. 感知机模型可解决的问题

&ensp;&ensp;每个模型的提出都是为了解决问题，感知机模型虽然简单，但是它也可以解决一些我们常见问题。下面我列举一个我们都清楚的简单逻辑电路**与**运算, **与**操作的表格如下:

| x1 | x2 | θ |
| ------ | ------ | ------ |
| 0 | 0 | 0 |
| 1 | 0 | 0 |
| 0 | 1 | 0 |
| 1 | 1 | 1 |

为了满足上面表格的内容，我们设置(w<sub>1</sub>, w<sub>2</sub>, θ) = (0.5,0.5, 0.6), 这样仅当x<sub>1</sub>和x<sub>2</sub>同时为1时，信号的加权总和才会超过阈值θ。 同理，我们也可以得到可以完成**或**运算的(w<sub>1</sub>, w<sub>2</sub>, θ)。

&ensp;&ensp; 虽然上述的过程十分简单，不过为了统一这里还是写一下代码吧，这段代码主要对不太了解numpy的读者看看, 代码在```perceptron.py```。

## 3. 感知机的局限性

我们代码中写了感知机实现与操作， 与非操作，或操作三种逻辑操作，这么简单的感知机一定有它不能实现的操作， 下面我门就点明它的局限性，来看**异或**操作的表格:

| x1 | x2 | θ |
| ------ | ------ | ------ |
| 0 | 0 | 0 |
| 1 | 0 | 1 |
| 0 | 1 | 1 |
| 1 | 1 | 0 |